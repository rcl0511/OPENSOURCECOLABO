# main.py
import os
import io
import re
import uuid
import time
import logging
from typing import Optional, List, Dict, Any, Tuple

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

from routes_auth import router as auth_router
from routes_medical import router as medical_router

from PIL import Image
from gtts import gTTS

import pandas as pd
from sentence_transformers import SentenceTransformer, util

from fastapi import FastAPI, UploadFile, File, Request, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles

# =========================================================
# 0) Í∏∞Î≥∏ ÏÑ§Ï†ï / Î°úÍπÖ
# =========================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
log = logging.getLogger("sosai-backend")

app = FastAPI(title="SOSAI Backend", version="1.0.0")

# =========================================================
# 1) ÌôòÍ≤ΩÎ≥ÄÏàò (Î∞∞Ìè¨ ÏπúÌôî)
# =========================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# CORS: Ïö¥ÏòÅÏóêÏÑúÎäî ÎèÑÎ©îÏù∏ÏúºÎ°ú Ï†úÌïú Í∂åÏû•
ALLOW_ORIGINS = os.getenv("ALLOW_ORIGINS", "https://sosaii.netlify.app").split(",")

# Ï†ïÏ†Å ÌååÏùº (mp3 Ï†ÄÏû•)
STATIC_DIR = os.getenv("STATIC_DIR", os.path.join(BASE_DIR, "static"))
os.makedirs(STATIC_DIR, exist_ok=True)
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# Î™®Îç∏/Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú
CLS_MODEL_PATH = os.getenv("CLS_MODEL_PATH", os.path.join(BASE_DIR, "best_model.pt"))
QA_EMBED_PKL = os.getenv("QA_EMBED_PKL", os.path.join(BASE_DIR, "ÌôîÏÉÅ_ÏßàÎ¨∏_with_embedding.pkl"))
QA_ANSWER_CSV = os.getenv("QA_ANSWER_CSV", os.path.join(BASE_DIR, "ÌôîÏÉÅ_ÎãµÎ≥Ä.csv"))

# Î∂ÑÎ•ò ÌÅ¥ÎûòÏä§
CLASS_NAMES = os.getenv("CLASS_NAMES", "1ÎèÑ,2ÎèÑ,3ÎèÑ").split(",")

# Î™®Îç∏ ÎîîÎ∞îÏù¥Ïä§
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# QnA Í≤∞Í≥º TopK Í∏∞Î≥∏Í∞í
DEFAULT_QNA_TOPK = int(os.getenv("QNA_TOPK", "3"))
# Ïú†ÏÇ¨ÎèÑ Í∏∞Ï§Ä(ÎÑàÎ¨¥ ÎÇÆÏùÄ Í≤É Í±∏Îü¨ÎÇ¥Í≥† Ïã∂ÏúºÎ©¥ ÏÇ¨Ïö©)
MIN_SIM = float(os.getenv("QNA_MIN_SIM", "0.0"))

# =========================================================
# 2) ÎØ∏Îì§Ïõ®Ïñ¥
# =========================================================
app.add_middleware(
    CORSMiddleware,
    allow_origins=[o.strip() for o in ALLOW_ORIGINS if o.strip()],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ÎùºÏö∞ÌÑ∞ Ìè¨Ìï®
app.include_router(auth_router)
app.include_router(medical_router)

# =========================================================
# 3) Ï†ÑÏ≤òÎ¶¨ / Ïú†Ìã∏
# =========================================================
img_transform = transforms.Compose(
    [
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)

def _safe_filename(ext: str) -> str:
    return f"{uuid.uuid4().hex}.{ext.lstrip('.')}"

def _normalize_text(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def _tts_to_static_mp3(text: str, lang: str = "ko") -> Optional[str]:
    """
    text -> mp3 Ï†ÄÏû• -> /static/xxx.mp3 Î∞òÌôò
    Ïã§Ìå®ÌïòÎ©¥ None
    """
    try:
        text = _normalize_text(text)
        if not text:
            return None
        fname = _safe_filename("mp3")
        out_path = os.path.join(STATIC_DIR, fname)
        gTTS(text=text, lang=lang).save(out_path)
        return f"/static/{fname}"
    except Exception:
        log.exception("TTS generation failed")
        return None

# =========================================================
# 4) Lazy Load (ÏÑúÎ≤Ñ Î∂ÄÌåÖ/Ïû¨ÏãúÏûë ÏïàÏ†ïÌôî)
# =========================================================
_cls_model: Optional[nn.Module] = None

_sbert: Optional[SentenceTransformer] = None
_q_embed: Optional[torch.Tensor] = None
_answers_df: Optional[pd.DataFrame] = None

def get_cls_model() -> nn.Module:
    global _cls_model
    if _cls_model is not None:
        return _cls_model

    if not os.path.exists(CLS_MODEL_PATH):
        raise FileNotFoundError(f"Classification model not found: {CLS_MODEL_PATH}")

    log.info(f"[CLS] Loading EfficientNet-B0 on {DEVICE} ...")
    model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)

    in_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(in_features, len(CLASS_NAMES))

    ckpt = torch.load(CLS_MODEL_PATH, map_location=DEVICE)

    if isinstance(ckpt, dict) and "state_dict" in ckpt:
        state = ckpt["state_dict"]
    else:
        state = ckpt

    cleaned = {}
    for k, v in state.items():
        nk = k.replace("module.", "")
        cleaned[nk] = v

    model.load_state_dict(cleaned, strict=False)
    model.to(DEVICE)
    model.eval()

    _cls_model = model
    log.info("[CLS] Model loaded.")
    return _cls_model

def get_qna_assets() -> Tuple[SentenceTransformer, torch.Tensor, pd.DataFrame]:
    global _sbert, _q_embed, _answers_df

    if _sbert is None:
        log.info("[QNA] Loading SentenceTransformer ...")
        _sbert = SentenceTransformer("jhgan/ko-sroberta-multitask", device=DEVICE)

    if _answers_df is None:
        if not os.path.exists(QA_ANSWER_CSV):
            raise FileNotFoundError(f"Answer CSV not found: {QA_ANSWER_CSV}")
        _answers_df = pd.read_csv(QA_ANSWER_CSV, encoding="utf-8")

    if _q_embed is None:
        if not os.path.exists(QA_EMBED_PKL):
            raise FileNotFoundError(f"Embedding PKL not found: {QA_EMBED_PKL}")
        _q_embed = torch.load(QA_EMBED_PKL, map_location=DEVICE)
        if isinstance(_q_embed, list):
            _q_embed = torch.tensor(_q_embed, device=DEVICE)
        if isinstance(_q_embed, torch.Tensor) and _q_embed.device.type != ("cuda" if DEVICE == "cuda" else "cpu"):
            _q_embed = _q_embed.to(DEVICE)

    return _sbert, _q_embed, _answers_df

def _get_question_col(df: pd.DataFrame) -> Optional[str]:
    for c in ["question", "ÏßàÎ¨∏", "Q", "Question", "Î¨∏Ìï≠", "query"]:
        if c in df.columns:
            return c
    return None

def _get_answer_col(df: pd.DataFrame) -> Optional[str]:
    for c in ["answer", "ÎãµÎ≥Ä", "A", "Answer", "ÏùëÎãµ", "response"]:
        if c in df.columns:
            return c
    return None

def qna_search(question: str, top_k: int = 3) -> List[Dict[str, Any]]:
    """
    question -> Ïú†ÏÇ¨ÎèÑ top_k Í≤∞Í≥º:
    [
      { "question": "...", "answer": "...", "similarity": 0.87, "index": 12 }
    ]
    """
    question = _normalize_text(question)
    if not question:
        return []

    sbert, q_embed, df = get_qna_assets()

    q_vec = sbert.encode(question, convert_to_tensor=True, device=DEVICE)
    sims = util.cos_sim(q_vec, q_embed)[0]  # (N,)

    k = max(1, min(int(top_k), sims.numel()))
    top_scores, top_indices = torch.topk(sims, k=k)

    q_col = _get_question_col(df)
    a_col = _get_answer_col(df)

    results: List[Dict[str, Any]] = []
    for score, idx in zip(top_scores.tolist(), top_indices.tolist()):
        if float(score) < MIN_SIM:
            continue

        row = df.iloc[int(idx)] if int(idx) < len(df) else None
        if row is None:
            continue

        q_text = str(row[q_col]) if q_col else ""
        a_text = str(row[a_col]) if a_col else str(row.iloc[0])

        results.append(
            {
                "index": int(idx),
                "similarity": float(score),
                "question": q_text,
                "answer": a_text,
            }
        )

    return results

# =========================================================
# 5) ÎùºÏö∞Ìä∏
# =========================================================
@app.get("/")
def root():
    return {"ok": True, "service": "SOSAI Backend", "device": DEVICE}

@app.get("/health")
def health():
    return {
        "ok": True,
        "device": DEVICE,
        "cls_model_exists": os.path.exists(CLS_MODEL_PATH),
        "qna_embed_exists": os.path.exists(QA_EMBED_PKL),
        "qna_answer_exists": os.path.exists(QA_ANSWER_CSV),
        "static_dir": STATIC_DIR,
        "allow_origins": ALLOW_ORIGINS,
    }

@app.post("/predict-image")
async def predict_image(file: UploadFile = File(...)):
    """
    ÌîÑÎ°†Ìä∏(VoicePage.jsx)Í∞Ä Í∏∞ÎåÄÌïòÎäî ÌòïÌÉúÎ°ú Î∞òÌôò:
    {
      prediction: 0/1/2,
      text: "...",
      top_similar_questions: [...],
      audio_url: "/static/xxx.mp3" (optional)
    }
    """
    t0 = time.time()
    try:
        model = get_cls_model()

        raw = await file.read()
        img = Image.open(io.BytesIO(raw)).convert("RGB")
        x = img_transform(img).unsqueeze(0).to(DEVICE)

        with torch.no_grad():
            logits = model(x)
            probs = torch.softmax(logits, dim=1)[0]

        pred_idx = int(torch.argmax(probs).item())

        # üî• Ïó¨Í∏∞ÏóêÏÑú ‚ÄúÏù¥ÎØ∏ÏßÄ ÏòàÏ∏° ÌõÑ Î≥¥Ïó¨Ï§Ñ ÌÖçÏä§Ìä∏‚ÄùÎ•º Í∞ÑÎã®Ìûà Íµ¨ÏÑ±
        label = CLASS_NAMES[pred_idx] if pred_idx < len(CLASS_NAMES) else str(pred_idx)
        text = f"ÏòàÏ∏° Í≤∞Í≥º: {label} (index={pred_idx})"

        # (ÏÑ†ÌÉù) TTS ÎßåÎì§Í≥† Ïã∂ÏúºÎ©¥ ÌôúÏÑ±Ìôî
        audio_url = None
        # audio_url = _tts_to_static_mp3(text)

        return {
            "prediction": pred_idx,
            "text": text,
            "top_similar_questions": [],
            "audio_url": audio_url,
            "elapsed_ms": int((time.time() - t0) * 1000),
        }

    except FileNotFoundError as e:
        return JSONResponse(status_code=503, content={"ok": False, "error": str(e)})
    except Exception as e:
        log.exception("predict_image failed")
        return JSONResponse(status_code=500, content={"ok": False, "error": str(e)})

@app.post("/answer")
async def answer(req: Request):
    """
    ÏöîÏ≤≠ ÏòàÏãú(JSON):
    {
      "question": "Î¨ºÏßëÏù¥ ÏÉùÍ≤ºÏñ¥Ïöî. Ïñ¥ÎñªÍ≤å Ìï¥ÏïºÌïòÎÇòÏöî?",
      "top_k": 1
    }
    """
    t0 = time.time()
    try:
        body = await req.json()
        question = _normalize_text(body.get("question", ""))
        top_k = int(body.get("top_k", 1))

        if not question:
            return JSONResponse(status_code=400, content={"ok": False, "error": "question is required"})

        results = qna_search(question, top_k=top_k)

        return {
            "ok": True,
            "question": question,
            "results": results,
            "best_answer": results[0]["answer"] if results else "",
            "elapsed_ms": int((time.time() - t0) * 1000),
        }

    except FileNotFoundError as e:
        return JSONResponse(status_code=503, content={"ok": False, "error": str(e)})
    except Exception as e:
        log.exception("answer failed")
        return JSONResponse(status_code=500, content={"ok": False, "error": str(e)})

@app.post("/dialog")
async def dialog(body: Dict[str, Any] = Body(...)):
    """
    ‚úÖ ÌîÑÎ°†Ìä∏(VoicePage.jsx) Ìò∏Ìôò ÏóîÎìúÌè¨Ïù∏Ìä∏
    ÌîÑÎ°†Ìä∏ ÏöîÏ≤≠: { "keyword": "..." }
    ÌîÑÎ°†Ìä∏ Í∏∞ÎåÄ ÏùëÎãµ:
      - answer (ÎòêÎäî text)
      - top_similar_questions: [{question, similarity}, ...]
      - audio_url(optional)

    ÌòÑÏû¨ ÌîÑÎ°†Ìä∏Îäî /dialogÎ°ú POST Î≥¥ÎÇ¥Í≥† bodyÏóê keywordÎ•º ÎÑ£Í≥† ÏûàÏùå.
    """
    t0 = time.time()
    try:
        keyword = _normalize_text(body.get("keyword", ""))
        top_k = int(body.get("top_k", DEFAULT_QNA_TOPK))

        if not keyword:
            return JSONResponse(status_code=400, content={"ok": False, "error": "keyword is required"})

        results = qna_search(keyword, top_k=top_k)

        best_answer = results[0]["answer"] if results else "Í¥ÄÎ†® ÎãµÎ≥ÄÏùÑ Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§."
        top_similar_questions = [
            {"question": r.get("question", ""), "similarity": float(r.get("similarity", 0.0))}
            for r in results
        ]

        # (ÏÑ†ÌÉù) ÎãµÎ≥ÄÏùÑ ÏùåÏÑ±ÏúºÎ°ú Ï£ºÍ≥† Ïã∂ÏúºÎ©¥ ÏºúÍ∏∞
        audio_url = None
        # audio_url = _tts_to_static_mp3(best_answer)

        return {
            "answer": best_answer,
            "top_similar_questions": top_similar_questions,
            "audio_url": audio_url,
            "elapsed_ms": int((time.time() - t0) * 1000),
        }

    except FileNotFoundError as e:
        return JSONResponse(status_code=503, content={"ok": False, "error": str(e)})
    except Exception as e:
        log.exception("dialog failed")
        return JSONResponse(status_code=500, content={"ok": False, "error": str(e)})

@app.post("/tts")
async def tts(req: Request):
    """
    ÏöîÏ≤≠ ÏòàÏãú(JSON):
    {
      "text": "ÏïàÎÖïÌïòÏÑ∏Ïöî. ÏùëÍ∏â Ï≤òÏπò ÏïàÎÇ¥Î•º ÏãúÏûëÌï©ÎãàÎã§.",
      "lang": "ko"
    }
    ÏùëÎãµ:
    {
      "ok": true,
      "url": "/static/xxxx.mp3"
    }
    """
    try:
        body = await req.json()
        text = _normalize_text(body.get("text", ""))
        lang = (body.get("lang") or "ko").strip()

        if not text:
            return JSONResponse(status_code=400, content={"ok": False, "error": "text is required"})

        fname = _safe_filename("mp3")
        out_path = os.path.join(STATIC_DIR, fname)

        tts_obj = gTTS(text=text, lang=lang)
        tts_obj.save(out_path)

        return {"ok": True, "url": f"/static/{fname}"}

    except Exception as e:
        log.exception("tts failed")
        return JSONResponse(status_code=500, content={"ok": False, "error": str(e)})

# =========================================================
# 6) Î°úÏª¨ Ïã§ÌñâÏö© (EC2ÏóêÏÑúÎäî Î≥¥ÌÜµ uvicornÏúºÎ°ú Ïã§Ìñâ)
# =========================================================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=int(os.getenv("PORT", "8000")), reload=False)
