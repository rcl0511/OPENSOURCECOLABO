from fastapi import FastAPI, Request, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles

from gtts import gTTS
from PIL import Image

import torchvision.transforms as transforms
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

import torch
import torch.nn as nn
import pandas as pd

import uuid
import os
import io
import re

from sentence_transformers import SentenceTransformer, util

# =================== ê¸°ë³¸ ì„¤ì • ===================
app = FastAPI()

# âœ… ìš´ì˜ì—ì„œëŠ” allow_originsë¥¼ Netlify ë„ë©”ì¸ìœ¼ë¡œ ì¢íˆëŠ” ê±¸ ì¶”ì²œ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë‚˜ì¤‘ì— ["https://sosaii.netlify.app"] ë¡œ ë³€ê²½ ì¶”ì²œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

BASE_DIR = os.path.dirname(__file__)

# ì •ì  íŒŒì¼ ì €ì¥ í´ë” ì„¤ì • (mp3 ì €ì¥)
STATIC_DIR = os.path.join(BASE_DIR, "static")
os.makedirs(STATIC_DIR, exist_ok=True)
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# =================== ë””ë°”ì´ìŠ¤ ===================
device = "cuda" if torch.cuda.is_available() else "cpu"

# =================================================
# 1) ì±—ë´‡(SBERT) ë¡œë”© (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒë§Œ)
# =================================================
MODEL_DIR = os.path.join(BASE_DIR, "models")
Q_PKL_PATH = os.path.join(MODEL_DIR, "í™”ìƒ_ì§ˆë¬¸_with_embedding.pkl")
A_CSV_PATH = os.path.join(MODEL_DIR, "í™”ìƒ_ë‹µë³€.csv")

text_model = None
df_q = None
df_a = None

def load_answer_csv(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path, encoding="cp949")
    except:
        return pd.read_csv(path, encoding="utf-8")

def preprocess(text: str) -> str:
    return re.sub(r"[^\w\s]", "", text).strip().lower()

def init_chatbot():
    global text_model, df_q, df_a

    # SBERT ëª¨ë¸ ë¡œë“œ
    text_model = SentenceTransformer("jhgan/ko-sroberta-multitask", device=device)

    # ë°ì´í„° ë¡œë“œ
    df_q = pd.read_pickle(Q_PKL_PATH)
    df_q["embedding"] = df_q["embedding"].apply(lambda x: torch.tensor(x).to(device))

    df_a = load_answer_csv(A_CSV_PATH)

    # ì§ˆí™˜_ì˜ë„ í‚¤ ìƒì„±
    for df in [df_q, df_a]:
        df["fileName"] = df["fileName"].astype(str).str.strip().str.upper()
        df["ì§ˆí™˜_ì˜ë„"] = df["disease_name"].astype(str).str.strip() + "_" + df["intention"].astype(str).str.strip()

    df_a["answer"] = df_a["answer"].fillna("")

def find_best_conditions(user_input: str, top_k=3):
    input_embedding = text_model.encode(preprocess(user_input), convert_to_tensor=True).to(device)
    similarities = [util.cos_sim(qe, input_embedding).item() for qe in df_q["embedding"]]
    top_indices = torch.topk(torch.tensor(similarities), top_k).indices.tolist()

    result = [{
        "question": df_q.iloc[idx]["question"],
        "condition_key": df_q.iloc[idx]["ì§ˆí™˜_ì˜ë„"],
        "similarity": round(similarities[idx], 4)
    } for idx in top_indices]

    return result, input_embedding

def get_best_answer(user_input: str):
    user_input = (user_input or "").strip()
    if not user_input:
        return {"answer": "âŒ ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ì–´ìš”.", "matches": [], "top_similar_questions": []}

    similar_info, input_embedding = find_best_conditions(user_input)
    condition_key = similar_info[0]["condition_key"]

    answer_df = df_a[df_a["ì§ˆí™˜_ì˜ë„"] == condition_key]
    if answer_df.empty:
        return {"answer": "âŒ í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤.", "matches": similar_info, "top_similar_questions": similar_info}

    priority_keywords = ['ì¡°ì¹˜', 'ì˜ˆë°©', 'ëŒ€ì‘', 'ì‘ê¸‰', 'ì²˜ì¹˜', 'ì´ˆê¸°', 'í•´ê²°', 'ëƒ‰ì°œì§ˆ', 'ë¬¼ë¡œ ì‹íˆê¸°', 'ì—°ê³ ', 'ë³‘ì›']
    filtered_df = answer_df[answer_df["answer"].str.contains("|".join(priority_keywords), na=False)]
    target_df = filtered_df if not filtered_df.empty else answer_df

    answer_texts = target_df["answer"].fillna("").tolist()
    answer_embeddings = text_model.encode(answer_texts, convert_to_tensor=True).to(device)
    sims = util.cos_sim(input_embedding, answer_embeddings)[0]
    best_idx = torch.argmax(sims).item()

    return {
        "answer": answer_texts[best_idx].strip() + " ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?",
        "matches": similar_info,
        "top_similar_questions": similar_info
    }

# FastAPI ì‹œì‘ ì‹œ ì±—ë´‡ ì´ˆê¸°í™”
@app.on_event("startup")
def on_startup():
    init_chatbot()
    init_image_model()

# =================================================
# 2) ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë”© (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒë§Œ)
# =================================================
image_model = None

def get_image_model(num_classes=3):
    weights = EfficientNet_B0_Weights.DEFAULT
    model = efficientnet_b0(weights=weights)
    in_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(in_features, num_classes)
    return model

def init_image_model():
    global image_model
    image_model = get_image_model()
    model_path = os.path.join(BASE_DIR, "best_model.pt")
    image_model.load_state_dict(torch.load(model_path, map_location=device))
    image_model.eval().to(device)

def run_image_predict(image: Image.Image) -> int:
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])
    tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        output = image_model(tensor)
        _, predicted = torch.max(output, 1)

    return int(predicted.item())

# =================================================
# 3) API
# =================================================
@app.post("/dialog")
async def dialog(request: Request):
    data = await request.json()
    keyword = data.get("keyword", "")

    result = get_best_answer(keyword)
    response_text = result.get("answer", "âŒ ì‘ë‹µì„ ë§Œë“¤ì§€ ëª»í–ˆì–´ìš”.")
    top_questions = result.get("top_similar_questions", [])

    # TTS mp3 ìƒì„±
    filename = f"{uuid.uuid4()}.mp3"
    filepath = os.path.join(STATIC_DIR, filename)
    gTTS(text=response_text, lang="ko").save(filepath)

    return JSONResponse({
        "text": response_text,
        "audio_url": f"/static/{filename}",
        "top_similar_questions": top_questions
    })

@app.post("/predict-image")
async def predict_image_api(file: UploadFile = File(...)):
    try:
        contents = await file.read()
        try:
            image = Image.open(io.BytesIO(contents)).convert("RGB")
        except Exception as e:
            return JSONResponse({"error": f"ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"}, status_code=400)

        pred = run_image_predict(image)

        return JSONResponse({
            "prediction": pred,
            "text": "ì‘ê¸‰ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤.",
            "audio_url": None,
            "top_similar_questions": []
        })
    except Exception as e:
        return JSONResponse({"error": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {e}"}, status_code=500)

@app.get("/")
def root():
    return {"message": "ğŸ”¥ SOSKIN FastAPI (ì±—ë´‡+TTS+ì´ë¯¸ì§€ì˜ˆì¸¡) ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}
