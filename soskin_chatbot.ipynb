{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcl0511/OPENSOURCECOLABO/blob/tts/soskin_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRPJik3ZpQr9",
        "outputId": "2a4784f5-dcd9-4e3d-8c38-8c3b3ec2eda1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "!pip install flask pyngrok sentence-transformers pandas torch\n",
        "!ngrok config add-authtoken &lt;your_personal_ngrok_auth_token&gt;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97bDywc2qbWT",
        "outputId": "64e952a5-90d1-4740-db53-93d26ef99d4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "# ðŸ”¹ ëª¨ë¸ ì„¤ì •\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "text_model = SentenceTransformer('jhgan/ko-sroberta-multitask', device=device)\n",
        "\n",
        "# ðŸ”¹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "def load_answer_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path, encoding='cp949')\n",
        "    except:\n",
        "        return pd.read_csv(path, encoding='utf-8')\n",
        "\n",
        "df_q = pd.read_pickle('/content/drive/MyDrive/ì˜¤í”ˆì†ŒìŠ¤/í™”ìƒ_ì§ˆë¬¸_with_embedding.pkl')\n",
        "df_q['embedding'] = df_q['embedding'].apply(lambda x: torch.tensor(x).to(device))\n",
        "df_a = load_answer_csv('/content/drive/MyDrive/ì˜¤í”ˆì†ŒìŠ¤/í™”ìƒ_ë‹µë³€.csv')\n",
        "\n",
        "# ðŸ”¹ ì§ˆí™˜_ì˜ë„ í‚¤ ìƒì„± (âš ï¸ ì—¬ê¸° ì¶”ê°€ë¨!)\n",
        "for df in [df_q, df_a]:\n",
        "    df['fileName'] = df['fileName'].astype(str).str.strip().str.upper()\n",
        "    df['ì§ˆí™˜_ì˜ë„'] = df['disease_name'].astype(str).str.strip() + \"_\" + df['intention'].astype(str).str.strip()\n",
        "df_a['answer'] = df_a['answer'].fillna('')\n",
        "\n",
        "# ðŸ”¹ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def preprocess(text):\n",
        "    return re.sub(r\"[^\\w\\s]\", \"\", text).strip().lower()\n",
        "\n",
        "def find_best_conditions(user_input, top_k=3):\n",
        "    input_embedding = text_model.encode(preprocess(user_input), convert_to_tensor=True).to(device)\n",
        "    similarities = [util.cos_sim(qe, input_embedding).item() for qe in df_q['embedding']]\n",
        "    top_indices = torch.topk(torch.tensor(similarities), top_k).indices.tolist()\n",
        "    result = [{\n",
        "        \"question\": df_q.iloc[idx]['question'],\n",
        "        \"condition_key\": df_q.iloc[idx]['ì§ˆí™˜_ì˜ë„'],\n",
        "        \"similarity\": round(similarities[idx], 4)\n",
        "    } for idx in top_indices]\n",
        "    return result, input_embedding\n",
        "\n",
        "def get_best_answer(user_input):\n",
        "    user_input = user_input.strip()\n",
        "    if not user_input:\n",
        "        return {\"answer\": \"âŒ ìž…ë ¥ëœ ë‚´ìš©ì´ ì—†ì–´ìš”.\", \"matches\": [], \"top_similar_questions\": []}\n",
        "\n",
        "    similar_info, input_embedding = find_best_conditions(user_input)\n",
        "    condition_key = similar_info[0]['condition_key']\n",
        "    answer_df = df_a[df_a['ì§ˆí™˜_ì˜ë„'] == condition_key]\n",
        "\n",
        "    if answer_df.empty:\n",
        "        return {\"answer\": \"âŒ í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤.\", \"matches\": similar_info, \"top_similar_questions\": similar_info}\n",
        "\n",
        "    priority_keywords = ['ì¡°ì¹˜', 'ì˜ˆë°©', 'ëŒ€ì‘', 'ì‘ê¸‰', 'ì²˜ì¹˜', 'ì´ˆê¸°', 'í•´ê²°', 'ëƒ‰ì°œì§ˆ', 'ë¬¼ë¡œ ì‹ížˆê¸°', 'ì—°ê³ ', 'ë³‘ì›']\n",
        "    filtered_df = answer_df[answer_df['answer'].str.contains('|'.join(priority_keywords), na=False)]\n",
        "    target_df = filtered_df if not filtered_df.empty else answer_df\n",
        "\n",
        "    answer_texts = target_df['answer'].fillna('').tolist()\n",
        "    answer_embeddings = text_model.encode(answer_texts, convert_to_tensor=True).to(device)\n",
        "    similarities = util.cos_sim(input_embedding, answer_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer_texts[best_idx].strip() + \" ë” ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ì‹ ê°€ìš”?\",\n",
        "        \"matches\": similar_info,\n",
        "        \"top_similar_questions\": similar_info\n",
        "    }\n",
        "\n",
        "# ðŸ”¹ ì´ë¯¸ì§€ ëª¨ë¸ ì„¤ì •\n",
        "def get_image_model(num_classes=3):\n",
        "    weights = EfficientNet_B0_Weights.DEFAULT\n",
        "    model = efficientnet_b0(weights=weights)\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "image_model = get_image_model()\n",
        "model_path = \"/content/drive/MyDrive/ì˜¤í”ˆì†ŒìŠ¤/best_model.pt\"\n",
        "image_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "image_model.eval().to(device)\n",
        "\n",
        "def predict_image(image_file):\n",
        "    image = Image.open(image_file).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = image_model(tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    return int(predicted.item())\n",
        "\n",
        "# ðŸ”¹ Flask ì„œë²„ ì •ì˜\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/answer\", methods=[\"POST\"])\n",
        "def answer_api():\n",
        "    data = request.get_json()\n",
        "    user_input = data.get(\"keyword\", \"\")\n",
        "    result = get_best_answer(user_input)\n",
        "    return jsonify(result)\n",
        "\n",
        "@app.route(\"/predict-image\", methods=[\"POST\"])\n",
        "def predict_image_api():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\": \"ì´ë¯¸ì§€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤\"}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "    try:\n",
        "        prediction = predict_image(file)\n",
        "        return jsonify({\"prediction\": prediction})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# ðŸ”¹ ngrok ì‹¤í–‰\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"âœ… ì„œë²„ ì£¼ì†Œ:\", public_url)\n",
        "app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30WEeAjc4ltW",
        "outputId": "23c8256b-673f-4cfb-95f8-8d2a8af9a20f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì„œë²„ ì£¼ì†Œ: NgrokTunnel: \"https://c66a-34-87-87-92.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 12:46:22] \"POST /answer HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 12:52:06] \"POST /answer HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 13:02:15] \"POST /answer HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 13:18:57] \"POST /answer HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 13:22:06] \"POST /answer HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 13:24:04] \"POST /answer HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 13:25:11] \"POST /answer HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 13:37:06] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}
